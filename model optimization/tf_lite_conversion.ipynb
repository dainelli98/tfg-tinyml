{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Conversion a TensorFlow Lite\n",
    "Se convierten los modelos de TensorFlow a TensorFlow Lite, generando en cada caso una versión cuantizada y una versión\n",
    "no cuantizada.\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from tf_lite_conversion import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Parámetros\n",
    "Parámetros para ajustar la conversión."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "project_dir = \"/home/daniel/PycharmProjects/tfg-tinyml\"\n",
    "\n",
    "saved_audio_models_dir = f\"{project_dir}/saved models/audio\"\n",
    "audio_model_name = \"ExtAudioDataModel\"\n",
    "audio_QAT_model_name = \"ExtAudioDataModelQAT\"\n",
    "audio_model_dir = f\"{saved_audio_models_dir}/tensorflow\"\n",
    "audio_model_output_dir = f\"{saved_audio_models_dir}/tensorflow lite\"\n",
    "audio_representative_dataset_dir = f\"{project_dir}/samples/external/audio/all\"\n",
    "\n",
    "saved_image_models_dir = f\"{project_dir}/saved models/image\"\n",
    "image_model_name = \"MicroImgDataModel\"\n",
    "image_QAT_model_name = \"MicroImgDataModelQAT\"\n",
    "image_model_dir = f\"{saved_image_models_dir}/tensorflow\"\n",
    "image_model_output_dir = f\"{saved_image_models_dir}/tensorflow lite\"\n",
    "image_representative_dataset_dir = f\"{project_dir}/samples/microcontroller/preprocessed image/all\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Carga de datasets representativos\n",
    "Se cargan los datasets que se usarán para ajustar la cuantización."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 343 files belonging to 3 classes.\n",
      "Using 16154 samples.\n",
      "WARNING:tensorflow:From /home/daniel/.local/lib/python3.8/site-packages/tensorflow/python/ops/parallel_for/pfor.py:2380: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:Using a while_loop for converting IO>AudioResample\n"
     ]
    }
   ],
   "source": [
    "image_representative_dataset = get_image_representative_dataset(image_representative_dataset_dir)\n",
    "audio_representative_dataset = get_audio_representative_dataset(audio_representative_dataset_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conversión de modelos\n",
    "Se aplica la conversión de modelos."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted. The model has been saved in /home/daniel/PycharmProjects/tfg-tinyml/saved models/audio/tensorflow lite/ExtAudioDataModel.tflite.\n",
      "\n",
      "\n",
      "Applying quantization to ExtAudioDataModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted. The model has been saved in /home/daniel/PycharmProjects/tfg-tinyml/saved models/audio/tensorflow lite/ExtAudioDataModelQuant.tflite.\n",
      "\n",
      "\n",
      "Applying quantization to ExtAudioDataModelQAT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted. The model has been saved in /home/daniel/PycharmProjects/tfg-tinyml/saved models/audio/tensorflow lite/ExtAudioDataModelQAT.tflite.\n",
      "\n",
      "\n",
      "Model converted. The model has been saved in /home/daniel/PycharmProjects/tfg-tinyml/saved models/image/tensorflow lite/MicroImgDataModel.tflite.\n",
      "\n",
      "\n",
      "Applying quantization to MicroImgDataModel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted. The model has been saved in /home/daniel/PycharmProjects/tfg-tinyml/saved models/image/tensorflow lite/MicroImgDataModelQuant.tflite.\n",
      "\n",
      "\n",
      "Applying quantization to MicroImgDataModelQAT.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model converted. The model has been saved in /home/daniel/PycharmProjects/tfg-tinyml/saved models/image/tensorflow lite/MicroImgDataModelQAT.tflite.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "convert_saved_model(audio_model_name, audio_model_dir, audio_model_output_dir)\n",
    "convert_saved_model(audio_model_name, audio_model_dir, audio_model_output_dir, quantize=True,\n",
    "                    representative_dataset=audio_representative_dataset)\n",
    "convert_saved_model(audio_QAT_model_name, audio_model_dir, audio_model_output_dir, quantize=True,\n",
    "                    representative_dataset=audio_representative_dataset)\n",
    "\n",
    "convert_saved_model(image_model_name, image_model_dir, image_model_output_dir)\n",
    "convert_saved_model(image_model_name, image_model_dir, image_model_output_dir, quantize=True,\n",
    "                    representative_dataset=image_representative_dataset)\n",
    "convert_saved_model(image_QAT_model_name, image_model_dir, image_model_output_dir, quantize=True,\n",
    "                    representative_dataset=image_representative_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}